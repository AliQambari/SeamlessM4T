{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# SPANISH/ FRENCH/ ITALIAN / PERSIAN / GERMAN / ENGLISH\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "IP91Ahz7ifHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q fairseq2==0.1.0 gradio==3.40.1\n",
        "!pip install -q git+https://github.com/camenduru/seamless_communication"
      ],
      "metadata": {
        "id": "azJIy2AUPc9X",
        "outputId": "9a08b599-f12b-4095-cdbe-4ada946e275f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.3/162.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m97.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.2/179.2 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.2/298.2 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.7/203.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.9/98.9 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for seamless-communication (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright (c) Meta Platforms, Inc. and affiliates\n",
        "# Edited by AQ\n",
        "from __future__ import annotations\n",
        "\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchaudio\n",
        "from huggingface_hub import hf_hub_download\n",
        "from seamless_communication.models.inference.translator import Translator\n",
        "\n",
        "DESCRIPTION = \"\"\"# SeamlessM4T\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "TASK_NAMES = [\n",
        "    \"S2ST (تبدیل گفتار به گفتار)\",\n",
        "    \"S2TT (تبدیل گفتار به متن)\",\n",
        "    \"T2ST (تبدیل متن به گفتار)\",\n",
        "    \"T2TT (ترجمه متن به متن)\",\n",
        "    \"ASR (تشخیص گفتار)\",\n",
        "]\n",
        "\n",
        "# Language dict\n",
        "language_code_to_name = {\n",
        "\n",
        "    \"deu\": \"German\",\n",
        "\n",
        "    \"eng\": \"English\",\n",
        "\n",
        "    \"fra\": \"French\",\n",
        "\n",
        "    \"ita\": \"Italian\",\n",
        "\n",
        "    \"pes\": \"Western Persian\",\n",
        "\n",
        "    \"spa\": \"Spanish\",\n",
        "\n",
        "}\n",
        "LANGUAGE_NAME_TO_CODE = {v: k for k, v in language_code_to_name.items()}\n",
        "\n",
        "# Source langs: S2ST / S2TT / ASR don't need source lang\n",
        "# T2TT / T2ST use this\n",
        "text_source_language_codes = [\n",
        "\n",
        "    \"deu\",\n",
        "\n",
        "    \"eng\",\n",
        "\n",
        "    \"fra\",\n",
        "\n",
        "    \"ita\",\n",
        "\n",
        "    \"pes\",\n",
        "\n",
        "    \"spa\",\n",
        "\n",
        "]\n",
        "TEXT_SOURCE_LANGUAGE_NAMES = sorted(\n",
        "    [language_code_to_name[code] for code in text_source_language_codes]\n",
        ")\n",
        "\n",
        "# Target langs:\n",
        "# S2ST / T2ST\n",
        "s2st_target_language_codes = [\n",
        "    \"eng\",\n",
        "\n",
        "    \"deu\",\n",
        "\n",
        "    \"fra\",\n",
        "\n",
        "    \"ita\",\n",
        "\n",
        "    \"pes\",\n",
        "\n",
        "    \"spa\",\n",
        "\n",
        "]\n",
        "S2ST_TARGET_LANGUAGE_NAMES = sorted(\n",
        "    [language_code_to_name[code] for code in s2st_target_language_codes]\n",
        ")\n",
        "# S2TT / ASR\n",
        "S2TT_TARGET_LANGUAGE_NAMES = TEXT_SOURCE_LANGUAGE_NAMES\n",
        "# T2TT\n",
        "T2TT_TARGET_LANGUAGE_NAMES = TEXT_SOURCE_LANGUAGE_NAMES\n",
        "\n",
        "AUDIO_SAMPLE_RATE = 16000.0\n",
        "MAX_INPUT_AUDIO_LENGTH = 60  # in seconds\n",
        "DEFAULT_TARGET_LANGUAGE = \"French\"\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "translator = Translator(\n",
        "    model_name_or_card=\"seamlessM4T_large\",\n",
        "    vocoder_name_or_card=\"vocoder_36langs\",\n",
        "    device=device,\n",
        "    dtype=torch.float16 if \"cuda\" in device.type else torch.float32,\n",
        ")\n",
        "\n",
        "def predict(\n",
        "    task_name: str,\n",
        "    audio_source: str,\n",
        "    input_audio_mic: str | None,\n",
        "    input_audio_file: str | None,\n",
        "    input_text: str | None,\n",
        "    source_language: str | None,\n",
        "    target_language: str,\n",
        ") -> tuple[tuple[int, np.ndarray] | None, str]:\n",
        "    task_name = task_name.split()[0]\n",
        "    source_language_code = (\n",
        "        LANGUAGE_NAME_TO_CODE[source_language] if source_language else None\n",
        "    )\n",
        "    target_language_code = LANGUAGE_NAME_TO_CODE[target_language]\n",
        "\n",
        "    if task_name in [\"S2ST\", \"S2TT\", \"ASR\"]:\n",
        "        if audio_source == \"microphone\":\n",
        "            input_data = input_audio_mic\n",
        "        else:\n",
        "            input_data = input_audio_file\n",
        "\n",
        "        arr, org_sr = torchaudio.load(input_data)\n",
        "        new_arr = torchaudio.functional.resample(\n",
        "            arr, orig_freq=org_sr, new_freq=AUDIO_SAMPLE_RATE\n",
        "        )\n",
        "        max_length = int(MAX_INPUT_AUDIO_LENGTH * AUDIO_SAMPLE_RATE)\n",
        "        if new_arr.shape[1] > max_length:\n",
        "            new_arr = new_arr[:, :max_length]\n",
        "            gr.Warning(\n",
        "                f\"Input audio is too long. Only the first {MAX_INPUT_AUDIO_LENGTH} seconds is used.\"\n",
        "            )\n",
        "        torchaudio.save(input_data, new_arr, sample_rate=int(AUDIO_SAMPLE_RATE))\n",
        "    else:\n",
        "        input_data = input_text\n",
        "    text_out, wav, sr = translator.predict(\n",
        "        input=input_data,\n",
        "        task_str=task_name,\n",
        "        tgt_lang=target_language_code,\n",
        "        src_lang=source_language_code,\n",
        "        ngram_filtering=True,\n",
        "    )\n",
        "    if task_name in [\"S2ST\", \"T2ST\"]:\n",
        "        return (sr, wav.cpu().detach().numpy()), text_out\n",
        "    else:\n",
        "        return None, text_out\n",
        "\n",
        "\n",
        "def process_s2st_example(\n",
        "    input_audio_file: str, target_language: str\n",
        ") -> tuple[tuple[int, np.ndarray] | None, str]:\n",
        "    return predict(\n",
        "        task_name=\"S2ST\",\n",
        "        audio_source=\"file\",\n",
        "        input_audio_mic=None,\n",
        "        input_audio_file=input_audio_file,\n",
        "        input_text=None,\n",
        "        source_language=None,\n",
        "        target_language=target_language,\n",
        "    )\n",
        "\n",
        "\n",
        "def process_s2tt_example(\n",
        "    input_audio_file: str, target_language: str\n",
        ") -> tuple[tuple[int, np.ndarray] | None, str]:\n",
        "    return predict(\n",
        "        task_name=\"S2TT\",\n",
        "        audio_source=\"file\",\n",
        "        input_audio_mic=None,\n",
        "        input_audio_file=input_audio_file,\n",
        "        input_text=None,\n",
        "        source_language=None,\n",
        "        target_language=target_language,\n",
        "    )\n",
        "\n",
        "\n",
        "def process_t2st_example(\n",
        "    input_text: str, source_language: str, target_language: str\n",
        ") -> tuple[tuple[int, np.ndarray] | None, str]:\n",
        "    return predict(\n",
        "        task_name=\"T2ST\",\n",
        "        audio_source=\"\",\n",
        "        input_audio_mic=None,\n",
        "        input_audio_file=None,\n",
        "        input_text=input_text,\n",
        "        source_language=source_language,\n",
        "        target_language=target_language,\n",
        "    )\n",
        "\n",
        "\n",
        "def process_t2tt_example(\n",
        "    input_text: str, source_language: str, target_language: str\n",
        ") -> tuple[tuple[int, np.ndarray] | None, str]:\n",
        "    return predict(\n",
        "        task_name=\"T2TT\",\n",
        "        audio_source=\"\",\n",
        "        input_audio_mic=None,\n",
        "        input_audio_file=None,\n",
        "        input_text=input_text,\n",
        "        source_language=source_language,\n",
        "        target_language=target_language,\n",
        "    )\n",
        "\n",
        "\n",
        "def process_asr_example(\n",
        "    input_audio_file: str, target_language: str\n",
        ") -> tuple[tuple[int, np.ndarray] | None, str]:\n",
        "    return predict(\n",
        "        task_name=\"ASR\",\n",
        "        audio_source=\"file\",\n",
        "        input_audio_mic=None,\n",
        "        input_audio_file=input_audio_file,\n",
        "        input_text=None,\n",
        "        source_language=None,\n",
        "        target_language=target_language,\n",
        "    )\n",
        "\n",
        "\n",
        "def update_audio_ui(audio_source: str) -> tuple[dict, dict]:\n",
        "    mic = audio_source == \"microphone\"\n",
        "    return (\n",
        "        gr.update(visible=mic, value=None),  # input_audio_mic\n",
        "        gr.update(visible=not mic, value=None),  # input_audio_file\n",
        "    )\n",
        "\n",
        "\n",
        "def update_input_ui(task_name: str) -> tuple[dict, dict, dict, dict]:\n",
        "    task_name = task_name.split()[0]\n",
        "    if task_name == \"S2ST\":\n",
        "        return (\n",
        "            gr.update(visible=True),  # audio_box\n",
        "            gr.update(visible=False),  # input_text\n",
        "            gr.update(visible=False),  # source_language\n",
        "            gr.update(\n",
        "                visible=True,\n",
        "                choices=S2ST_TARGET_LANGUAGE_NAMES,\n",
        "                value=DEFAULT_TARGET_LANGUAGE,\n",
        "            ),  # target_language\n",
        "        )\n",
        "    elif task_name == \"S2TT\":\n",
        "        return (\n",
        "            gr.update(visible=True),  # audio_box\n",
        "            gr.update(visible=False),  # input_text\n",
        "            gr.update(visible=False),  # source_language\n",
        "            gr.update(\n",
        "                visible=True,\n",
        "                choices=S2TT_TARGET_LANGUAGE_NAMES,\n",
        "                value=DEFAULT_TARGET_LANGUAGE,\n",
        "            ),  # target_language\n",
        "        )\n",
        "    elif task_name == \"T2ST\":\n",
        "        return (\n",
        "            gr.update(visible=False),  # audio_box\n",
        "            gr.update(visible=True),  # input_text\n",
        "            gr.update(visible=True),  # source_language\n",
        "            gr.update(\n",
        "                visible=True,\n",
        "                choices=S2ST_TARGET_LANGUAGE_NAMES,\n",
        "                value=DEFAULT_TARGET_LANGUAGE,\n",
        "            ),  # target_language\n",
        "        )\n",
        "    elif task_name == \"T2TT\":\n",
        "        return (\n",
        "            gr.update(visible=False),  # audio_box\n",
        "            gr.update(visible=True),  # input_text\n",
        "            gr.update(visible=True),  # source_language\n",
        "            gr.update(\n",
        "                visible=True,\n",
        "                choices=T2TT_TARGET_LANGUAGE_NAMES,\n",
        "                value=DEFAULT_TARGET_LANGUAGE,\n",
        "            ),  # target_language\n",
        "        )\n",
        "    elif task_name == \"ASR\":\n",
        "        return (\n",
        "            gr.update(visible=True),  # audio_box\n",
        "            gr.update(visible=False),  # input_text\n",
        "            gr.update(visible=False),  # source_language\n",
        "            gr.update(\n",
        "                visible=True,\n",
        "                choices=S2TT_TARGET_LANGUAGE_NAMES,\n",
        "                value=DEFAULT_TARGET_LANGUAGE,\n",
        "            ),  # target_language\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown task: {task_name}\")\n",
        "\n",
        "\n",
        "def update_output_ui(task_name: str) -> tuple[dict, dict]:\n",
        "    task_name = task_name.split()[0]\n",
        "    if task_name in [\"S2ST\", \"T2ST\"]:\n",
        "        return (\n",
        "            gr.update(visible=True, value=None),  # output_audio\n",
        "            gr.update(value=None),  # output_text\n",
        "        )\n",
        "    elif task_name in [\"S2TT\", \"T2TT\", \"ASR\"]:\n",
        "        return (\n",
        "            gr.update(visible=False, value=None),  # output_audio\n",
        "            gr.update(value=None),  # output_text\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown task: {task_name}\")\n",
        "\n",
        "\n",
        "def update_example_ui(task_name: str) -> tuple[dict, dict, dict, dict, dict]:\n",
        "    task_name = task_name.split()[0]\n",
        "    return (\n",
        "        gr.update(visible=task_name == \"S2ST\"),  # s2st_example_row\n",
        "        gr.update(visible=task_name == \"S2TT\"),  # s2tt_example_row\n",
        "        gr.update(visible=task_name == \"T2ST\"),  # t2st_example_row\n",
        "        gr.update(visible=task_name == \"T2TT\"),  # t2tt_example_row\n",
        "        gr.update(visible=task_name == \"ASR\"),  # asr_example_row\n",
        "    )\n",
        "\n",
        "\n",
        "css = \"\"\"\n",
        "h1 {\n",
        "  text-align: center;\n",
        "}\n",
        "\n",
        ".contain {\n",
        "  max-width: 730px;\n",
        "  margin: auto;\n",
        "  padding-top: 1.5rem;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "with gr.Blocks(css=css) as demo:\n",
        "    gr.Markdown(DESCRIPTION)\n",
        "    with gr.Group():\n",
        "        task_name = gr.Dropdown(\n",
        "            label=\"Task\",\n",
        "            choices=TASK_NAMES,\n",
        "            value=TASK_NAMES[0],\n",
        "        )\n",
        "        with gr.Row():\n",
        "            source_language = gr.Dropdown(\n",
        "                label=\"Source language\",\n",
        "                choices=TEXT_SOURCE_LANGUAGE_NAMES,\n",
        "                value=\"English\",\n",
        "                visible=False,\n",
        "            )\n",
        "            target_language = gr.Dropdown(\n",
        "                label=\"Target language\",\n",
        "                choices=S2ST_TARGET_LANGUAGE_NAMES,\n",
        "                value=DEFAULT_TARGET_LANGUAGE,\n",
        "            )\n",
        "        with gr.Row() as audio_box:\n",
        "            audio_source = gr.Radio(\n",
        "                label=\"Audio source\",\n",
        "                choices=[\"file\", \"microphone\"],\n",
        "                value=\"file\",\n",
        "            )\n",
        "            input_audio_mic = gr.Audio(\n",
        "                label=\"Input speech\",\n",
        "                type=\"filepath\",\n",
        "                source=\"microphone\",\n",
        "                visible=False,\n",
        "            )\n",
        "            input_audio_file = gr.Audio(\n",
        "                label=\"Input speech\",\n",
        "                type=\"filepath\",\n",
        "                source=\"upload\",\n",
        "                visible=True,\n",
        "            )\n",
        "        input_text = gr.Textbox(label=\"Input text\", visible=False)\n",
        "        btn = gr.Button(\"Translate\")\n",
        "        with gr.Column():\n",
        "            output_audio = gr.Audio(\n",
        "                label=\"Translated speech\",\n",
        "                autoplay=False,\n",
        "                streaming=False,\n",
        "                type=\"numpy\",\n",
        "            )\n",
        "            output_text = gr.Textbox(label=\"Translated text\")\n",
        "\n",
        "    audio_source.change(\n",
        "        fn=update_audio_ui,\n",
        "        inputs=audio_source,\n",
        "        outputs=[\n",
        "            input_audio_mic,\n",
        "            input_audio_file,\n",
        "        ],\n",
        "        queue=False,\n",
        "        api_name=False,\n",
        "    )\n",
        "    task_name.change(\n",
        "        fn=update_input_ui,\n",
        "        inputs=task_name,\n",
        "        outputs=[\n",
        "            audio_box,\n",
        "            input_text,\n",
        "            source_language,\n",
        "            target_language,\n",
        "        ],\n",
        "        queue=False,\n",
        "        api_name=False,\n",
        "    ).then(\n",
        "        fn=update_output_ui,\n",
        "        inputs=task_name,\n",
        "        outputs=[output_audio, output_text],\n",
        "        queue=False,\n",
        "        api_name=False,\n",
        "    )\n",
        "\n",
        "    btn.click(\n",
        "        fn=predict,\n",
        "        inputs=[\n",
        "            task_name,\n",
        "            audio_source,\n",
        "            input_audio_mic,\n",
        "            input_audio_file,\n",
        "            input_text,\n",
        "            source_language,\n",
        "            target_language,\n",
        "        ],\n",
        "        outputs=[output_audio, output_text],\n",
        "        api_name=\"run\",\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.queue().launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "id": "u2wgQSZHZ6ZI",
        "outputId": "c897f572-acf1-4384-8846-809940bbe7db"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading the checkpoint of the model 'seamlessM4T_large'...\n",
            "100%|██████████| 10.7G/10.7G [01:03<00:00, 180MB/s]\n",
            "Downloading the tokenizer of the model 'seamlessM4T_large'...\n",
            "100%|██████████| 4.93M/4.93M [00:00<00:00, 61.1MB/s]\n",
            "Downloading the checkpoint of the model 'vocoder_36langs'...\n",
            "100%|██████████| 160M/160M [00:01<00:00, 88.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://a643f110164258704e.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a643f110164258704e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}