{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q fairseq2==0.1.0 gradio==3.40.1\n",
        "!pip install -q git+https://github.com/camenduru/seamless_communication"
      ],
      "metadata": {
        "id": "azJIy2AUPc9X",
        "outputId": "653f748e-9831-4192-a458-0dd4d48e686f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchaudio\n",
        "from huggingface_hub import hf_hub_download\n",
        "from seamless_communication.models.inference.translator import Translator\n",
        "DESCRIPTION = \"\"\"# SeamlessM4T\n",
        "Persian / English / Spanish / French / German\n",
        " \"\"\"\n",
        "TASK_NAMES = [\n",
        "    \"S2ST (Speech to Speech translation)\",\n",
        "    \"S2TT (Speech to Text translation)\",\n",
        "    \"T2ST (Text to Speech translation)\",\n",
        "    \"T2TT (Text to Text translation)\",\n",
        "    \"ASR (Automatic Speech Recognition)\",\n",
        "]\n",
        "# Language dict\n",
        "language_code_to_name = {\n",
        "\n",
        "    \"deu\": \"German\",\n",
        "    \"eng\": \"English\",\n",
        "    \"fra\": \"French\",\n",
        "    \"ita\": \"Italian\",\n",
        "    \"pes\": \"Western Persian\",\n",
        "    \"spa\": \"Spanish\",\n",
        "}\n",
        "LANGUAGE_NAME_TO_CODE = {v: k for k, v in language_code_to_name.items()}\n",
        "\n",
        "text_source_language_codes = [\n",
        "    \"deu\",\n",
        "    \"eng\",\n",
        "    \"fra\",\n",
        "    \"ita\",\n",
        "    \"pes\",\n",
        "    \"spa\",\n",
        "]\n",
        "TEXT_SOURCE_LANGUAGE_NAMES = sorted(\n",
        "    [language_code_to_name[code] for code in text_source_language_codes]\n",
        ")\n",
        "\n",
        "s2st_target_language_codes = [\n",
        "    \"eng\",\n",
        "    \"fra\",\n",
        "    \"ita\",\n",
        "    \"pes\",\n",
        "    \"spa\",\n",
        "    \"deu\",\n",
        "]\n",
        "S2ST_TARGET_LANGUAGE_NAMES = sorted(\n",
        "    [language_code_to_name[code] for code in s2st_target_language_codes]\n",
        ")\n",
        "# S2TT / ASR\n",
        "S2TT_TARGET_LANGUAGE_NAMES = TEXT_SOURCE_LANGUAGE_NAMES\n",
        "# T2TT\n",
        "T2TT_TARGET_LANGUAGE_NAMES = TEXT_SOURCE_LANGUAGE_NAMES\n",
        "\n",
        "\n",
        "AUDIO_SAMPLE_RATE = 16000.0\n",
        "MAX_INPUT_AUDIO_LENGTH = 60  # in seconds\n",
        "DEFAULT_TARGET_LANGUAGE = \"French\"\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "translator = Translator(\n",
        "    model_name_or_card=\"seamlessM4T_large\",\n",
        "    vocoder_name_or_card=\"vocoder_36langs\",\n",
        "    device=device,\n",
        "    dtype=torch.float16 if \"cuda\" in device.type else torch.float32,\n",
        ")\n",
        "\n",
        "\n",
        "def predict(\n",
        "    task_name: str,\n",
        "    audio_source: str,\n",
        "    input_audio_mic: str | None,\n",
        "    input_audio_file: str | None,\n",
        "    input_text: str | None,\n",
        "    source_language: str | None,\n",
        "    target_language: str,\n",
        ") -> tuple[tuple[int, np.ndarray] | None, str]:\n",
        "    task_name = task_name.split()[0]\n",
        "    source_language_code = (\n",
        "        LANGUAGE_NAME_TO_CODE[source_language] if source_language else None\n",
        "    )\n",
        "    target_language_code = LANGUAGE_NAME_TO_CODE[target_language]\n",
        "\n",
        "    if task_name in [\"S2ST\", \"S2TT\", \"ASR\"]:\n",
        "        if audio_source == \"microphone\":\n",
        "            input_data = input_audio_mic\n",
        "        else:\n",
        "            input_data = input_audio_file\n",
        "\n",
        "        arr, org_sr = torchaudio.load(input_data)\n",
        "        new_arr = torchaudio.functional.resample(\n",
        "            arr, orig_freq=org_sr, new_freq=AUDIO_SAMPLE_RATE\n",
        "        )\n",
        "        max_length = int(MAX_INPUT_AUDIO_LENGTH * AUDIO_SAMPLE_RATE)\n",
        "        if new_arr.shape[1] > max_length:\n",
        "            new_arr = new_arr[:, :max_length]\n",
        "            gr.Warning(\n",
        "                f\"Input audio is too long. Only the first {MAX_INPUT_AUDIO_LENGTH} seconds is used.\"\n",
        "            )\n",
        "        torchaudio.save(input_data, new_arr, sample_rate=int(AUDIO_SAMPLE_RATE))\n",
        "    else:\n",
        "        input_data = input_text\n",
        "    text_out, wav, sr = translator.predict(\n",
        "        input=input_data,\n",
        "        task_str=task_name,\n",
        "        tgt_lang=target_language_code,\n",
        "        src_lang=source_language_code,\n",
        "        ngram_filtering=True,\n",
        "    )\n",
        "    if task_name in [\"S2ST\", \"T2ST\"]:\n",
        "        return (sr, wav.cpu().detach().numpy()), text_out\n",
        "    else:\n",
        "        return None, text_out\n",
        "def process_s2st_example(\n",
        "    input_audio_file: str, target_language: str\n",
        ") -> tuple[tuple[int, np.ndarray] | None, str]:\n",
        "    return predict(\n",
        "        task_name=\"S2ST\",\n",
        "        audio_source=\"file\",\n",
        "        input_audio_mic=None,\n",
        "        input_audio_file=input_audio_file,\n",
        "        input_text=None,\n",
        "        source_language=None,\n",
        "        target_language=target_language,\n",
        "    )\n",
        "\n",
        "def process_s2tt_example(\n",
        "    input_audio_file: str, target_language: str\n",
        ") -> tuple[tuple[int, np.ndarray] | None, str]:\n",
        "    return predict(\n",
        "        task_name=\"S2TT\",\n",
        "        audio_source=\"file\",\n",
        "        input_audio_mic=None,\n",
        "        input_audio_file=input_audio_file,\n",
        "        input_text=None,\n",
        "        source_language=None,\n",
        "        target_language=target_language,\n",
        "    )\n",
        "def process_t2st_example(\n",
        "    input_text: str, source_language: str, target_language: str\n",
        ") -> tuple[tuple[int, np.ndarray] | None, str]:\n",
        "    return predict(\n",
        "        task_name=\"T2ST\",\n",
        "        audio_source=\"\",\n",
        "        input_audio_mic=None,\n",
        "        input_audio_file=None,\n",
        "        input_text=input_text,\n",
        "        source_language=source_language,\n",
        "        target_language=target_language,\n",
        "    )\n",
        "def process_t2tt_example(\n",
        "    input_text: str, source_language: str, target_language: str\n",
        ") -> tuple[tuple[int, np.ndarray] | None, str]:\n",
        "    return predict(\n",
        "        task_name=\"T2TT\",\n",
        "        audio_source=\"\",\n",
        "        input_audio_mic=None,\n",
        "        input_audio_file=None,\n",
        "        input_text=input_text,\n",
        "        source_language=source_language,\n",
        "        target_language=target_language,\n",
        "    )\n",
        "\n",
        "\n",
        "def process_asr_example(\n",
        "    input_audio_file: str, target_language: str\n",
        ") -> tuple[tuple[int, np.ndarray] | None, str]:\n",
        "    return predict(\n",
        "        task_name=\"ASR\",\n",
        "        audio_source=\"file\",\n",
        "        input_audio_mic=None,\n",
        "        input_audio_file=input_audio_file,\n",
        "        input_text=None,\n",
        "        source_language=None,\n",
        "        target_language=target_language,\n",
        "    )\n",
        "def update_audio_ui(audio_source: str) -> tuple[dict, dict]:\n",
        "    mic = audio_source == \"microphone\"\n",
        "    return (\n",
        "        gr.update(visible=mic, value=None),  # input_audio_mic\n",
        "        gr.update(visible=not mic, value=None),  # input_audio_file\n",
        "    )\n",
        "def update_input_ui(task_name: str) -> tuple[dict, dict, dict, dict]:\n",
        "    task_name = task_name.split()[0]\n",
        "    if task_name == \"S2ST\":\n",
        "        return (\n",
        "            gr.update(visible=True),  # audio_box\n",
        "            gr.update(visible=False),  # input_text\n",
        "            gr.update(visible=False),  # source_language\n",
        "            gr.update(\n",
        "                visible=True,\n",
        "                choices=S2ST_TARGET_LANGUAGE_NAMES,\n",
        "                value=DEFAULT_TARGET_LANGUAGE,\n",
        "            ),  # target_language\n",
        "        )\n",
        "    elif task_name == \"S2TT\":\n",
        "        return (\n",
        "            gr.update(visible=True),  # audio_box\n",
        "            gr.update(visible=False),  # input_text\n",
        "            gr.update(visible=False),  # source_language\n",
        "            gr.update(\n",
        "                visible=True,\n",
        "                choices=S2TT_TARGET_LANGUAGE_NAMES,\n",
        "                value=DEFAULT_TARGET_LANGUAGE,\n",
        "            ),  # target_language\n",
        "        )\n",
        "    elif task_name == \"T2ST\":\n",
        "        return (\n",
        "            gr.update(visible=False),  # audio_box\n",
        "            gr.update(visible=True),  # input_text\n",
        "            gr.update(visible=True),  # source_language\n",
        "            gr.update(\n",
        "                visible=True,\n",
        "                choices=S2ST_TARGET_LANGUAGE_NAMES,\n",
        "                value=DEFAULT_TARGET_LANGUAGE,\n",
        "            ),  # target_language\n",
        "        )\n",
        "    elif task_name == \"T2TT\":\n",
        "        return (\n",
        "            gr.update(visible=False),  # audio_box\n",
        "            gr.update(visible=True),  # input_text\n",
        "            gr.update(visible=True),  # source_language\n",
        "            gr.update(\n",
        "                visible=True,\n",
        "                choices=T2TT_TARGET_LANGUAGE_NAMES,\n",
        "                value=DEFAULT_TARGET_LANGUAGE,\n",
        "            ),  # target_language\n",
        "        )\n",
        "    elif task_name == \"ASR\":\n",
        "        return (\n",
        "            gr.update(visible=True),  # audio_box\n",
        "            gr.update(visible=False),  # input_text\n",
        "            gr.update(visible=False),  # source_language\n",
        "            gr.update(\n",
        "                visible=True,\n",
        "                choices=S2TT_TARGET_LANGUAGE_NAMES,\n",
        "                value=DEFAULT_TARGET_LANGUAGE,\n",
        "            ),  # target_language\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown task: {task_name}\")\n",
        "\n",
        "\n",
        "def update_output_ui(task_name: str) -> tuple[dict, dict]:\n",
        "    task_name = task_name.split()[0]\n",
        "    if task_name in [\"S2ST\", \"T2ST\"]:\n",
        "        return (\n",
        "            gr.update(visible=True, value=None),  # output_audio\n",
        "            gr.update(value=None),  # output_text\n",
        "        )\n",
        "    elif task_name in [\"S2TT\", \"T2TT\", \"ASR\"]:\n",
        "        return (\n",
        "            gr.update(visible=False, value=None),  # output_audio\n",
        "            gr.update(value=None),  # output_text\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown task: {task_name}\")\n",
        "\n",
        "\n",
        "def update_example_ui(task_name: str) -> tuple[dict, dict, dict, dict, dict]:\n",
        "    task_name = task_name.split()[0]\n",
        "    return (\n",
        "        gr.update(visible=task_name == \"S2ST\"),  # s2st_example_row\n",
        "        gr.update(visible=task_name == \"S2TT\"),  # s2tt_example_row\n",
        "        gr.update(visible=task_name == \"T2ST\"),  # t2st_example_row\n",
        "        gr.update(visible=task_name == \"T2TT\"),  # t2tt_example_row\n",
        "        gr.update(visible=task_name == \"ASR\"),  # asr_example_row\n",
        "    )\n",
        "css = \"\"\"\n",
        "h1 {\n",
        "  text-align: center;\n",
        "}\n",
        "\n",
        ".contain {\n",
        "  max-width: 730px;\n",
        "  margin: auto;\n",
        "  padding-top: 1.5rem;\n",
        "}\n",
        "\"\"\"\n",
        "with gr.Blocks(css=css) as demo:\n",
        "    gr.Markdown(DESCRIPTION)\n",
        "    with gr.Group():\n",
        "        task_name = gr.Dropdown(\n",
        "            label=\"Task\",\n",
        "            choices=TASK_NAMES,\n",
        "            value=TASK_NAMES[0],\n",
        "        )\n",
        "        with gr.Row():\n",
        "            source_language = gr.Dropdown(\n",
        "                label=\"Source language\",\n",
        "                choices=TEXT_SOURCE_LANGUAGE_NAMES,\n",
        "                value=\"English\",\n",
        "                visible=False,\n",
        "            )\n",
        "            target_language = gr.Dropdown(\n",
        "                label=\"Target language\",\n",
        "                choices=S2ST_TARGET_LANGUAGE_NAMES,\n",
        "                value=DEFAULT_TARGET_LANGUAGE,\n",
        "            )\n",
        "        with gr.Row() as audio_box:\n",
        "            audio_source = gr.Radio(\n",
        "                label=\"Audio source\",\n",
        "                choices=[\"file\", \"microphone\"],\n",
        "                value=\"file\",\n",
        "            )\n",
        "            input_audio_mic = gr.Audio(\n",
        "                label=\"Input speech\",\n",
        "                type=\"filepath\",\n",
        "                source=\"microphone\",\n",
        "                visible=False,\n",
        "            )\n",
        "            input_audio_file = gr.Audio(\n",
        "                label=\"Input speech\",\n",
        "                type=\"filepath\",\n",
        "                source=\"upload\",\n",
        "                visible=True,\n",
        "            )\n",
        "        input_text = gr.Textbox(label=\"Input text\", visible=False)\n",
        "        btn = gr.Button(\"Translate\")\n",
        "        with gr.Column():\n",
        "            output_audio = gr.Audio(\n",
        "                label=\"Translated speech\",\n",
        "                autoplay=False,\n",
        "                streaming=False,\n",
        "                type=\"numpy\",\n",
        "            )\n",
        "            output_text = gr.Textbox(label=\"Translated text\")\n",
        "    audio_source.change(\n",
        "        fn=update_audio_ui,\n",
        "        inputs=audio_source,\n",
        "        outputs=[\n",
        "            input_audio_mic,\n",
        "            input_audio_file,\n",
        "        ],\n",
        "        queue=False,\n",
        "        api_name=False,\n",
        "    )\n",
        "    task_name.change(\n",
        "        fn=update_input_ui,\n",
        "        inputs=task_name,\n",
        "        outputs=[\n",
        "            audio_box,\n",
        "            input_text,\n",
        "            source_language,\n",
        "            target_language,\n",
        "        ],\n",
        "        queue=False,\n",
        "        api_name=False,\n",
        "    ).then(\n",
        "        fn=update_output_ui,\n",
        "        inputs=task_name,\n",
        "        outputs=[output_audio, output_text],\n",
        "        queue=False,\n",
        "        api_name=False,\n",
        "    )\n",
        "    btn.click(\n",
        "        fn=predict,\n",
        "        inputs=[\n",
        "            task_name,\n",
        "            audio_source,\n",
        "            input_audio_mic,\n",
        "            input_audio_file,\n",
        "            input_text,\n",
        "            source_language,\n",
        "            target_language,\n",
        "        ],\n",
        "        outputs=[output_audio, output_text],\n",
        "        api_name=\"run\",\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.queue().launch()"
      ],
      "metadata": {
        "id": "cYVkh0bcPT4N"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}